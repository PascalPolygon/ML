{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARN-ONE-RULE(T~~~~~~~~~~~U~~, Attributes, Examples, k)\n",
    "    Returns a single rule that covers some of the Examples. Conducts a generalJotospec$c\n",
    "    greedy beam search for the best rule, guided by the PERFORMANCE metric.\n",
    "    a Initialize Besthypothesis to the most general hypothesis 0\n",
    "    a Initialize Candidatehypotheses to the set (Besthypothesis)\n",
    "    a While Candidatehypotheses is not empty, Do\n",
    "        I. Generate the next more spec@ candidatehypotheses\n",
    "        a Allronstraints c the set of all constraints of the form (a = v), where a is a member\n",
    "        of Attributes, and v is a value of a that occurs in the current set of Examples\n",
    "        a Newrandidatehypotheses c\n",
    "        for each h in Candidatehypotheses,\n",
    "        for each c in Alll-onstraints,\n",
    "        create a specialization of h by adding the constraint c\n",
    "        a Remove from Newl-andidatehypotheses any hypotheses that are duplicates, inconsistent, or not maximally specific\n",
    "    2. Update Besthypothesis\n",
    "        a For all h in Newnandidatehypotheses do\n",
    "        a If PERFORMANCE(^, Examples, Targetattribute)\n",
    "        z PERFORMANCE(Besthypothesis, Examples, Targetattribute))\n",
    "        Then Besthypothesis t h\n",
    "    3. Update Candidatehypotheses\n",
    "        a Candidatehypotheses c the k best members of New-candidatehypotheses, according\n",
    "        to the PERFORMANCE measure.\n",
    "        a Return a rule of the form\n",
    "        \"IF Best hypothesis THEN prediction\"\n",
    "        where prediction is the most frequent value of Targetattribute among those Examples\n",
    "        that match Besthypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.4\n",
    "A 3x2x1 Neural Network as 11 weights inlcluding the bias units' weights. We can representent the value of each weight as a binary string using the IEEE 754 format. Then a hypothesis would be represented as bit string containing 352 bits. That is, 11 concatenated 32 bit strings. As the size of any hypothesis of this type will have a fixed number of 352 bits. We can use the regular single-point, double point and uniform crossover techniques as well as single point mutation. However, single-point and double point crossover are likely to cover the exponent part of IEEE 754 representation, thus producing offsprings that are vastly different from their parents. To ensure that the hypothesis search converges, it is desirable to avoid performing cross over the exponent part of the 32 bit binary representation. For this reason, uniform cross over modified to ommit bits 30 through 23 of each 32 bit segment is chosen as the crossover operator.\n",
    "\n",
    "Because GA keeps a serveral high-performing hypotheses at each iteration, it is less likely than BackPropagation to get stuck at a local minimum. However, performing operations on serveral hypotheses instead of one comes at the cost of running time, making GA much slower than BackPropagation.\n",
    "\n",
    "# 10.1\n",
    "- $2^d -1$ rules will be formed\n",
    "- Each rule will posess $d-1$ preconditions\n",
    "- It is challenging to determine how many choices seq-covering will make, because seq-convering generates rules until a performance threshold is met. \n",
    "\n",
    "Seq-covering is more prone to overfitting because decisions about rules are made on smaller subset of rules compared to ID3. seq-covering will output set of rules that have high accuracy on the data they cover but have low coverage (They do not cover many examples)\n",
    "\n",
    "# 10.3\n",
    "- Add User_constraints input parameter to Learn-One-Rule function ```(LEARN-ONE-RULE(Target_attribute, Attributes, Examples, k, User_constraints))```\n",
    "- Under the following line:\n",
    "\n",
    "```Allcronstraints <- the set of all constraints of the form (a = v), where a is a member of Attributes, and v is a value of a that occurs in the current set of Examples ```\n",
    "\n",
    "add\n",
    "```\n",
    "for c in Allconstraints\n",
    "    for u_c in User_constraints\n",
    "        if c.attribute == u_c.attribute\n",
    "            c = u_c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A 3x2x1 Neural Network "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
